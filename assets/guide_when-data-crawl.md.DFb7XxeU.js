import{_ as e,c as r,o as l,ag as i}from"./chunks/framework.B3HI_LuJ.js";const u=JSON.parse('{"title":"2-数据采集中的挑战与解决方案","description":"","frontmatter":{},"headers":[],"relativePath":"guide/when-data-crawl.md","filePath":"guide/when-data-crawl.md","lastUpdated":1748174751000}'),o={name:"guide/when-data-crawl.md"};function t(n,a,p,h,s,c){return l(),r("div",null,a[0]||(a[0]=[i('<h1 id="_2-数据采集中的挑战与解决方案" tabindex="-1">2-数据采集中的挑战与解决方案 <a class="header-anchor" href="#_2-数据采集中的挑战与解决方案" aria-label="Permalink to &quot;2-数据采集中的挑战与解决方案&quot;">​</a></h1><p>在数据采集过程中，无论是通过 API 还是浏览器自动化，开发者都可能面临一系列复杂的问题。LibianCrawler 针对这些挑战提供了更加稳健和灵活的解决方案。</p><h2 id="基于-api-的数据采集" tabindex="-1">基于 API 的数据采集 <a class="header-anchor" href="#基于-api-的数据采集" aria-label="Permalink to &quot;基于 API 的数据采集&quot;">​</a></h2><h3 id="理想情况下的-api-数据采集" tabindex="-1">理想情况下的 API 数据采集 <a class="header-anchor" href="#理想情况下的-api-数据采集" aria-label="Permalink to &quot;理想情况下的 API 数据采集&quot;">​</a></h3><p>当目标平台的 API 没有复杂的加密机制（如 sign 签名算法），或者已经有成熟的 API SDK 可以直接使用时，数据采集工作会变得非常顺畅。</p><p>在这种情况下，传统方案能够高效完成数据采集任务。</p><p>LibianCrawler 为 API 采集封装了常用功能，例如:</p><ul><li>在采集阶段，封装了参数相似的高层 API，提供了通用的工具库。</li><li>在清洗阶段，数据清洗 CI 依然可以为一些“面向dict编程”的API提供强类型。并分门别类的输出清洗后的列对齐结果。</li></ul><h3 id="当需要进行-javascript-逆向工程寻找-api-签名算法时" tabindex="-1">当需要进行 JavaScript 逆向工程寻找 API 签名算法时 <a class="header-anchor" href="#当需要进行-javascript-逆向工程寻找-api-签名算法时" aria-label="Permalink to &quot;当需要进行 JavaScript 逆向工程寻找 API 签名算法时&quot;">​</a></h3><p>当 API 存在复杂的 sign 签名算法时，传统方案通常会选择逆向这些算法。 这是一项极其繁琐且耗时的工作，因为开发者需要与一个甚至数十个平台方的安全团队展开“军备竞赛”。</p><p>因此，LibianCrawler 采用了更为保护个人开发者头发总量的方案 —— 直接从浏览器 Frames DOM 树中获取内容，避免逆向复杂算法。</p><p>请参见下文。</p><h2 id="基于浏览器自动化的数据采集" tabindex="-1">基于浏览器自动化的数据采集 <a class="header-anchor" href="#基于浏览器自动化的数据采集" aria-label="Permalink to &quot;基于浏览器自动化的数据采集&quot;">​</a></h2><p>尽管浏览器自动化技术已经非常成熟，但在实际应用中仍然面临以下挑战：</p><h3 id="dom-元素的提取" tabindex="-1">DOM 元素的提取 <a class="header-anchor" href="#dom-元素的提取" aria-label="Permalink to &quot;DOM 元素的提取&quot;">​</a></h3><p>传统方案通常直接使用 XPath 或选择器从 DOM 中提取特定元素，将采集和清洗步骤合为一体。这种方法存在一个致命问题：</p><ul><li><strong>对网页结构高度依赖</strong>：当目标网站更新其页面布局时，采集程序可能会完全失效。</li></ul><p>LibianCrawler 的解决方案：</p><ul><li>在采集阶段，只负责将所有内容（如 DOM、API 响应）保存下来，而不直接提取特定字段。</li><li>在清洗阶段，专门处理数据提取工作。当网页更新时，只需修改清洗逻辑，而采集程序可以继续运行。</li></ul><p>这种方法的优势：</p><ul><li>网页更新时，采集程序不需要停止。</li><li>清洗程序会通过类型检查自动检测结构变化。如果业务代码仍可复用，则无需调整；否则会停止清洗以待修复。</li></ul><h3 id="处理弹出式验证" tabindex="-1">处理弹出式验证 <a class="header-anchor" href="#处理弹出式验证" aria-label="Permalink to &quot;处理弹出式验证&quot;">​</a></h3><p>传统方案和 LibianCrawler 在处理弹出式验证时采用了相似的方法，即:</p><ul><li>检测到特定情形时，暂停采集程序并弹出对话框和通知，等待程序员手动处理。</li></ul><p>但 LibianCrawler 在未来可能会开发更完善的分布式解决方案。</p><h3 id="防止反爬虫指纹检测" tabindex="-1">防止反爬虫指纹检测 <a class="header-anchor" href="#防止反爬虫指纹检测" aria-label="Permalink to &quot;防止反爬虫指纹检测&quot;">​</a></h3><p>LibianCrawler 使用 <a href="https://camoufox.com/" target="_blank" rel="noreferrer">Camoufox</a> 规避浏览器指纹检测。</p><div class="tip custom-block"><p class="custom-block-title">Why Camoufox</p><p><a href="https://camoufox.com/" target="_blank" rel="noreferrer">Camoufox</a> 旨在成为一款具有强大指纹注入和反机器人逃避功能的简约浏览器。</p></div><h4 id="在-api-采集时同样修改指纹" tabindex="-1">在 API 采集时同样修改指纹 <a class="header-anchor" href="#在-api-采集时同样修改指纹" aria-label="Permalink to &quot;在 API 采集时同样修改指纹&quot;">​</a></h4><p>在使用 API 采集数据时，LibianCrawler 会尽可能的 Hook API 库中的 http 请求，并挑选 proxy、tls 指纹、header，<strong>但是这项功能尚未开发完成</strong>。</p><h4 id="统一-proxy-geo-font-locale" tabindex="-1">统一 proxy,geo,font,locale <a class="header-anchor" href="#统一-proxy-geo-font-locale" aria-label="Permalink to &quot;统一 proxy,geo,font,locale&quot;">​</a></h4><p>LibianCrawler 还会维护 代理池+指纹库，并确保 geoip、proxy-ip、locale、font 等环境参数相互印证，<strong>但是这项功能尚未开发完成</strong>。</p><p>Locale 设置也应当传给数据清洗 CI 以便在清洗时提供当地的日期，<strong>但是这项功能尚未开发完成</strong>。</p><h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h2><p>在数据采集领域，LibianCrawler 通过以下方式显著优化了传统解决方案：</p><ul><li>避免复杂逆向工作：直接从浏览器环境中获取数据。</li><li>分离采集与清洗：减少对目标平台结构变化的敏感度。</li><li>灵活性和扩展性：支持分布式任务调度、多种存储后端以及自定义反反爬虫策略。</li></ul><p>通过这些特性，LibianCrawler 能够显著提高数据采集的稳定性和效率，同时降低维护成本。</p>',37)]))}const b=e(o,[["render",t]]);export{u as __pageData,b as default};
