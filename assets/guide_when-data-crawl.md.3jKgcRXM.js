import{_ as i,c as e,o as r,ag as l}from"./chunks/framework.B3HI_LuJ.js";const u=JSON.parse('{"title":"2-数据采集中的挑战与解决方案","description":"","frontmatter":{},"headers":[],"relativePath":"guide/when-data-crawl.md","filePath":"guide/when-data-crawl.md","lastUpdated":1743241315000}'),t={name:"guide/when-data-crawl.md"};function o(n,a,p,s,h,c){return r(),e("div",null,a[0]||(a[0]=[l('<h1 id="_2-数据采集中的挑战与解决方案" tabindex="-1">2-数据采集中的挑战与解决方案 <a class="header-anchor" href="#_2-数据采集中的挑战与解决方案" aria-label="Permalink to &quot;2-数据采集中的挑战与解决方案&quot;">​</a></h1><p>在数据采集过程中，无论是通过 API 还是浏览器自动化，开发者都可能面临一系列复杂的问题。LibianCrawler 针对这些挑战提供了更加稳健和灵活的解决方案。</p><h2 id="基于-api-的数据采集" tabindex="-1">基于 API 的数据采集 <a class="header-anchor" href="#基于-api-的数据采集" aria-label="Permalink to &quot;基于 API 的数据采集&quot;">​</a></h2><h3 id="理想情况下的-api-数据采集" tabindex="-1">理想情况下的 API 数据采集 <a class="header-anchor" href="#理想情况下的-api-数据采集" aria-label="Permalink to &quot;理想情况下的 API 数据采集&quot;">​</a></h3><p>当目标平台的 API 没有复杂的加密机制（如 sign 签名算法），或者已经有成熟的 API SDK 可以直接使用时，数据采集工作会变得非常顺畅。</p><p>在这种情况下，传统方案能够高效完成数据采集任务。</p><div class="tip custom-block"><p class="custom-block-title">LibianCrawler 为 API 采集提供了常用功能</p><ul><li>提供分布式爬虫的上下文存储设施，避免重复爬取。</li><li>支持任务的暂停与恢复，提高采集的灵活性。</li><li>封装了常用平台的 API 库，提供简洁的命令行接口，便于任务调度。</li></ul></div><h3 id="当需要进行-javascript-逆向工程寻找-api-签名算法时" tabindex="-1">当需要进行 JavaScript 逆向工程寻找 API 签名算法时 <a class="header-anchor" href="#当需要进行-javascript-逆向工程寻找-api-签名算法时" aria-label="Permalink to &quot;当需要进行 JavaScript 逆向工程寻找 API 签名算法时&quot;">​</a></h3><p>当 API 存在复杂的 sign 签名算法时，传统方案通常会选择逆向这些算法。这是一项极其繁琐且耗时的工作，因为开发者需要与平台方的安全团队展开“军备竞赛”。</p><p>因此，LibianCrawler 采用了更为稳健的方案：</p><ul><li>直接从浏览器 DOM 树中获取内容，避免逆向复杂算法。</li><li>Hook 浏览器环境下的 API 调用和请求，不再依赖 sign 算法的逆向。</li></ul><h2 id="基于浏览器自动化的数据采集" tabindex="-1">基于浏览器自动化的数据采集 <a class="header-anchor" href="#基于浏览器自动化的数据采集" aria-label="Permalink to &quot;基于浏览器自动化的数据采集&quot;">​</a></h2><p>尽管浏览器自动化技术已经非常成熟，但在实际应用中仍然面临以下挑战：</p><h3 id="dom-元素的提取" tabindex="-1">DOM 元素的提取 <a class="header-anchor" href="#dom-元素的提取" aria-label="Permalink to &quot;DOM 元素的提取&quot;">​</a></h3><p>传统方案通常直接使用 XPath 或选择器从 DOM 中提取特定元素，将采集和清洗步骤合为一体。这种方法存在一个致命问题：</p><ul><li><strong>对网页结构高度依赖</strong>：当目标网站更新其页面布局时，采集程序可能会完全失效。</li></ul><p>LibianCrawler 的解决方案：</p><ul><li>在采集阶段，只负责将所有内容（如 DOM、API 响应）保存下来，而不直接提取特定字段。</li><li>在清洗阶段，专门处理数据提取工作。当网页更新时，只需修改清洗逻辑，而采集程序可以继续运行。</li></ul><p>这种方法的优势：</p><ul><li>网页更新时，采集程序不需要停止。</li><li>清洗程序会通过类型检查自动检测结构变化。如果业务代码仍可复用，则无需调整；否则会停止清洗以待修复。</li></ul><h3 id="处理弹出式验证" tabindex="-1">处理弹出式验证 <a class="header-anchor" href="#处理弹出式验证" aria-label="Permalink to &quot;处理弹出式验证&quot;">​</a></h3><p>传统方案和 LibianCrawler 在处理弹出式验证时采用了相似的方法，但 LibianCrawler 在未来可能会开发更完善的分布式解决方案。</p><h3 id="防止反爬虫指纹检测" tabindex="-1">防止反爬虫指纹检测 <a class="header-anchor" href="#防止反爬虫指纹检测" aria-label="Permalink to &quot;防止反爬虫指纹检测&quot;">​</a></h3><p>LibianCrawler 使用 <a href="https://camoufox.com/" target="_blank" rel="noreferrer">Camoufox</a> 规避浏览器指纹检测。</p><div class="tip custom-block"><p class="custom-block-title">安利: Why Camoufox</p><p><a href="https://camoufox.com/" target="_blank" rel="noreferrer">Camoufox</a> 旨在成为一款具有强大指纹注入和反机器人逃避功能的简约浏览器。</p></div><p>在使用 API 采集数据时，LibianCrawler 会尽可能的 Hook API 库中的 http 请求，并挑选 proxy、tls 指纹、header，<strong>但是这项功能尚未开发完成</strong>。</p><p>LibianCrawler 还会维护 代理池+指纹库，并确保 geoip、proxy-ip、locale、font 等环境参数相互印证，<strong>但是这项功能尚未开发完成</strong>。</p><h2 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h2><p>在数据采集领域，LibianCrawler 通过以下方式显著优化了传统解决方案：</p><ul><li>避免复杂逆向工作：直接从浏览器环境中获取数据。</li><li>分离采集与清洗：减少对目标平台结构变化的敏感度。</li><li>灵活性和扩展性：支持分布式任务调度、多种存储后端以及自定义反反爬虫策略。</li></ul><p>通过这些特性，LibianCrawler 能够显著提高数据采集的稳定性和效率，同时降低维护成本。</p>',31)]))}const b=i(t,[["render",o]]);export{u as __pageData,b as default};
