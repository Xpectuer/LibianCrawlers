import{_ as s,c as i,o as e,a3 as n}from"./chunks/framework.w8luOYmq.js";const o=JSON.parse('{"title":"3.2-命令行启动第三方爬虫或数据源","description":"","frontmatter":{},"headers":[],"relativePath":"develop/crawler/start-crawl/third-part-crawler-integration.md","filePath":"develop/crawler/start-crawl/third-part-crawler-integration.md","lastUpdated":1762876666000}'),l={name:"develop/crawler/start-crawl/third-part-crawler-integration.md"};function r(t,a,p,h,d,c){return e(),i("div",null,a[0]||(a[0]=[n(`<h1 id="_3-2-命令行启动第三方爬虫或数据源" tabindex="-1">3.2-命令行启动第三方爬虫或数据源 <a class="header-anchor" href="#_3-2-命令行启动第三方爬虫或数据源" aria-label="Permalink to &quot;3.2-命令行启动第三方爬虫或数据源&quot;">​</a></h1><div class="danger custom-block"><p class="custom-block-title">DANGER</p><p>请务必阅读 <a href="./../crawler-and-criminal-law.html"><strong>《数据爬虫的罪与罚》</strong></a> 以了解法律风险。</p><p>如果你的爬虫违反了上文中的 <a href="./../crawler-and-criminal-law.html#禁区"><strong>禁区</strong></a>，请勿 PR 到此仓库，我也不会给你提供任何工具。</p><p>请务必参考 <a href="./../crawler-and-criminal-law.html#禁区"><strong>禁区</strong></a> 了解法律风险。</p></div><p>为了保护头发，我很想集成一下他人的优秀作品。</p><h2 id="github-com-suqingdong-impactfactor-搜索文献" tabindex="-1">github.com/suqingdong/impactfactor 搜索文献 <a class="header-anchor" href="#github-com-suqingdong-impactfactor-搜索文献" aria-label="Permalink to &quot;github.com/suqingdong/impactfactor 搜索文献&quot;">​</a></h2><p>项目地址:</p><ul><li><a href="https://github.com/suqingdong/impact_factor" target="_blank" rel="noreferrer">https://github.com/suqingdong/impact_factor</a></li></ul><p>启动方法参见文档:</p><ul><li><a href="./start-crawl.html#github-com-suqingdong-impact-factor">github-com-suqingdong-impact-factor</a></li></ul><h2 id="mediacrawler" tabindex="-1">MediaCrawler <a class="header-anchor" href="#mediacrawler" aria-label="Permalink to &quot;MediaCrawler&quot;">​</a></h2><div class="info custom-block"><p class="custom-block-title">客观评价</p><p><a href="https://github.com/NanmiCoder/MediaCrawler" target="_blank" rel="noreferrer">MediaCrawler</a> 可以爬取 <a href="https://github.com/NanmiCoder/MediaCrawler?tab=readme-ov-file#-%E5%8A%9F%E8%83%BD%E7%89%B9%E6%80%A7" target="_blank" rel="noreferrer">其声明的平台</a>， <strong>但部分平台仍然会风控账号导致爬取中止</strong>。</p><ul><li>20251029 <ul><li>快手、知乎 应该是比较稳定能爬的。</li><li>小红书、抖音、贴吧 容易风控。</li><li>B 站没试过。</li><li>微博 已经不行了。</li></ul></li></ul><p>尚待补充...</p></div><div class="tip custom-block"><p class="custom-block-title">使用 MediaCrawler 代码必须遵循以下条款</p><ul><li><a href="https://github.com/NanmiCoder/MediaCrawler?tab=readme-ov-file#disclaimer" target="_blank" rel="noreferrer">免责声明</a></li><li><a href="https://github.com/NanmiCoder/MediaCrawler?tab=License-1-ov-file#readme" target="_blank" rel="noreferrer">许可证</a></li></ul></div><h3 id="集成方法" tabindex="-1">集成方法 <a class="header-anchor" href="#集成方法" aria-label="Permalink to &quot;集成方法&quot;">​</a></h3><p>在 数据清洗CI 中，可以直接使用 Kysely 工具集读取其保存的 <code>database/sqlite_tables.db</code> 数据库文件，并清洗为想要的数据类型。</p><p>这里以在 <code>user_code/</code> 下的类型定义文件片段示例。</p><div class="language-typescript vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">typescript</span><pre class="shiki shiki-themes github-light github-dark has-diff vp-code" tabindex="0"><code><span class="line diff add"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> { read_media_crawler_from_sqlite } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;../general_data_process/media_crawler_integration/read_from_sqlite.ts&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; </span></span>
<span class="line diff add"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> { MediaCrawlerYield } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;../general_data_process/media_crawler_integration/util.ts&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 此函数封装了读取 MediaCrawler 项目的本地 sqlite ， </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 并转换为 AsyncGenerator&lt;MediaCrawlerYield[]&gt;</span></span>
<span class="line diff add"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">async</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> function*</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> my_media_crawler_datasets</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">() {  </span></span>
<span class="line diff add"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  yield*</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> read_media_crawler_from_sqlite</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">({      </span></span>
<span class="line diff add"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    libsql_url: </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 这里默认在 LibianCrawlers/.data 下初始化了一个 MediaCrawler 项目仓库。</span></span>
<span class="line diff add"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">      &quot;file:C:/data/LibianCrawlers/.data/MediaCrawler/database/sqlite_tables.db&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span></span>
<span class="line diff add"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  });                                          </span></span>
<span class="line diff add"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}                                              </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">//TJLibianCrawlerGarbage</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> type</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> LibianCrawlerGarbage</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span></span>
<span class="line diff add"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  |</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MediaCrawlerYield</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">export</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> read_LibianCrawlerGarbage</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span></span>
<span class="line diff add"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1919810</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, my_media_crawler_datasets], </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 这里将 MediaCrawler 的数据集生成器并入总数据集。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> const</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><h3 id="相关代码" tabindex="-1">相关代码 <a class="header-anchor" href="#相关代码" aria-label="Permalink to &quot;相关代码&quot;">​</a></h3><p>从 sqlite 读取数据，并对其格式进行转换的代码参考此处:</p><ul><li><a href="https://github.com/Xpectuer/LibianCrawlers/blob/main/data_cleaner_ci/general_data_process/media_crawler_integration/read_from_sqlite.ts" target="_blank" rel="noreferrer">https://github.com/Xpectuer/LibianCrawlers/blob/main/data_cleaner_ci/general_data_process/media_crawler_integration/read_from_sqlite.ts</a></li></ul>`,18)]))}const g=s(l,[["render",r]]);export{o as __pageData,g as default};
